{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Configuration"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "\n",
      "path = \"/Users/bryanfeeney/Desktop/SmallerDB-NoCJK-WithFeats-Fixed\"\n",
      "codePath = \"/Users/bryanfeeney/Workspace/sidetopics/src\"\n",
      "reconstructSparse=False\n",
      "\n",
      "sys.path.append(codePath)\n",
      "%run /Users/bryanfeeney/Desktop/SmallerDB-NoCJK-WithFeats-Fixed/dicts.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 141
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Prelude"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import numpy.random as rd\n",
      "import scipy as sp\n",
      "import scipy.linalg as la\n",
      "import scipy.sparse as ssp\n",
      "import scipy.sparse.linalg as sla\n",
      "import pickle as pkl\n",
      "import matplotlib.pyplot as plt\n",
      "import os\n",
      "%matplotlib inline\n",
      "\n",
      "import pickle as pkl\n",
      "import bottleneck\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 142
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Basic Data Analysis\n",
      "## Load the data\n",
      "Optionally we may reconstruct the sparse matrices from the individual dense numpy objects. These are then dumped back to disk, overwriting the old ones."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if reconstructSparse:\n",
      "    W_data = np.load(path + \"/words-data.npy\")\n",
      "    W_ind  = np.load(path + \"/words-indices.npy\")\n",
      "    W_ptr  = np.load(path + \"/words-indptr.npy\")\n",
      "\n",
      "    X_data = np.load(path + \"/side-data.npy\")\n",
      "    X_ind  = np.load(path + \"/side-indices.npy\")\n",
      "    X_ptr  = np.load(path + \"/side-indptr.npy\")\n",
      "\n",
      "    W = ssp.csr_matrix((W_data, W_ind, W_ptr))\n",
      "    X = ssp.csr_matrix((X_data, X_ind, X_ptr))\n",
      "\n",
      "    with open(path + \"/words.pkl\", 'wb') as f:\n",
      "        pkl.dump(ssp.csr_matrix((W_data, W_ind, W_ptr)), f)\n",
      "\n",
      "    with open(path + \"/side.pkl\", 'wb') as f:\n",
      "        pkl.dump(ssp.csr_matrix((X_data, X_ind, X_ptr)), f)\n",
      "\n",
      "    (W.shape, X.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 143
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open(path + \"/words.pkl\", 'rb') as f:\n",
      "    W = pkl.load(f)\n",
      "with open(path + \"/side.pkl\", 'rb') as f:\n",
      "    X = pkl.load(f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 144
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##\u00a0Document Count and Length\n",
      "Document, feature and term counts. Total word-count. Distribution over document lengths."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(D,T) = W.shape\n",
      "(D_check,F) = X.shape\n",
      "\n",
      "\n",
      "(D, D_check == D, T, F)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 145,
       "text": [
        "(575591, True, 79799, 420)"
       ]
      }
     ],
     "prompt_number": 145
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.sum(W.data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 146,
       "text": [
        "5560927"
       ]
      }
     ],
     "prompt_number": 146
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "docLen = np.squeeze(np.asarray (W.sum(axis=1)))\n",
      "np.where(docLen < 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 147,
       "text": [
        "(array([], dtype=int64),)"
       ]
      }
     ],
     "prompt_number": 147
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig, ax = plt.subplots()\n",
      "counts, bins, patches = ax.hist(docLen, bins=40, range=(0,40))\n",
      "ax.set_xlabel(\"Token Count\")\n",
      "ax.set_ylabel(\"Tweet Count\")\n",
      "pass"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEPCAYAAABlZDIgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x10e3caf10>"
       ]
      }
     ],
     "prompt_number": 148
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note that tweets containing fewer than four tokens were not admitted to the dataset when preprocessing, which is why this graph starts at 4 and not 0 or 1"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Word-Counts and Dictionary Sizes\n",
      "Total dictionary size, and dictionary size per token type"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import itertools\n",
      "d = list(itertools.chain.from_iterable(words))\n",
      "len(d)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 149,
       "text": [
        "79800"
       ]
      }
     ],
     "prompt_number": 149
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dictNames = ['Addressee', 'URL', 'Text', 'Stock', 'Emoticon', 'Hashtag']\n",
      "dicts     = [ wordsUsername, wordsUrl, wordsToken, wordsStock, wordsEmoticon, wordsHashtag, ]\n",
      "dictLens  = dict (zip(dictNames, [len(w) for w in dicts]))\n",
      "dictLens"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 150,
       "text": [
        "{'Addressee': 0,\n",
        " 'Emoticon': 593,\n",
        " 'Hashtag': 13347,\n",
        " 'Stock': 454,\n",
        " 'Text': 63421,\n",
        " 'URL': 1985}"
       ]
      }
     ],
     "prompt_number": 150
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For convenience later define the start and end of each token type, so we can slice the word matrix and just do inference, on for example, hashtags."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dictStarts = dict()\n",
      "acc = 0\n",
      "for k in dictNames:\n",
      "    dictStarts[k] = acc\n",
      "    acc += dictLens[k]\n",
      "dictStarts\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 151,
       "text": [
        "{'Addressee': 0,\n",
        " 'Emoticon': 65860,\n",
        " 'Hashtag': 66453,\n",
        " 'Stock': 65406,\n",
        " 'Text': 1985,\n",
        " 'URL': 0}"
       ]
      }
     ],
     "prompt_number": 151
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dictEnds = dict()\n",
      "for i in range(len(dictNames) - 1):\n",
      "    dictEnds[dictNames[i]] = dictStarts[dictNames[i + 1]]\n",
      "dictEnds[dictNames[-1]] = len(d)\n",
      "dictEnds"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 152,
       "text": [
        "{'Addressee': 0,\n",
        " 'Emoticon': 66453,\n",
        " 'Hashtag': 79800,\n",
        " 'Stock': 65860,\n",
        " 'Text': 65406,\n",
        " 'URL': 1985}"
       ]
      }
     ],
     "prompt_number": 152
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###\u00a0Sanity check"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Just to verify that the words have been adequately extracted, we recreate a tweet from its vector representation using the dictionary. We already know that the first row in the document-term matrix $W$ corresponds to the first tweet from the ACLU account, which reads:\n",
      "\n",
      "> Sen. Lautenberg was a champion for religious liberty, women's rights & reproductive freedom. We will miss his voice & passion."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[d[i] for i in W.indices[0:W.indptr[1]]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 153,
       "text": [
        "['we',\n",
        " 'women',\n",
        " 'hi',\n",
        " 'liberti',\n",
        " 'passion',\n",
        " 'miss',\n",
        " 'champion',\n",
        " 'voic',\n",
        " 'reproduct',\n",
        " 'religi',\n",
        " 'freedom',\n",
        " 'sen',\n",
        " 'lautenberg',\n",
        " 'right']"
       ]
      }
     ],
     "prompt_number": 153
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###\u00a0Minimum and Maximum Count of Each Class of Token"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "totalCount = np.squeeze(np.asarray (W.astype(np.int32).sum(axis=0)))\n",
      "\n",
      "totalCounts = dict()\n",
      "endExcl = 0\n",
      "for i in range(len(dicts)):\n",
      "    name = dictNames[i]\n",
      "    startIncl  = endExcl\n",
      "    endExcl   += len(dicts[i])\n",
      "    totalCounts[name] = totalCount[startIncl:endExcl]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 154
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for k,v in totalCounts.items():\n",
      "    dict_k = dicts[dictNames.index(k)]\n",
      "    print (\"Min(%s): count = %d, token = %s\" % (k , v.min() if len(v) > 0 else -1, dict_k[v.argmin()] if len(v) > 0 else \"\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Min(Stock): count = 0, token = $nq\n",
        "Min(URL): count = 0, token = http://www.youtube.com/watch?v=nYu6hfmVZk8\n",
        "Min(Addressee): count = -1, token = \n",
        "Min(Hashtag): count = 0, token = #dfmchat\n",
        "Min(Text): count = 0, token = 3\n",
        "Min(Emoticon): count = 0, token = \u00a7\n"
       ]
      }
     ],
     "prompt_number": 155
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for k,v in totalCounts.items():\n",
      "    dict_k = dicts[dictNames.index(k)]\n",
      "    print (\"Max(%s): count = %d, token = %s\" % (k , v.max() if len(v) > 0 else -1, dict_k[v.argmax()] if len(v) > 0 else \"\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Max(Stock): count = 561, token = $aapl\n",
        "Max(URL): count = 435, token = http://dirtywars.org\n",
        "Max(Addressee): count = -1, token = \n",
        "Max(Hashtag): count = 3727, token = #usopen\n",
        "Max(Text): count = 98298, token = you\n",
        "Max(Emoticon): count = 17023, token = :)\n"
       ]
      }
     ],
     "prompt_number": 156
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note that the emoticon is actually a supplemental unicode character, which Python here has failed to display correctly."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Graph of Token Frequency\n",
      "The following graph is slightly confusing - it counts how many words occur how many times, with occurrence count on the Y axis and unique word count on the X axis"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figRows = len([l for l in dictLens.values() if l > 0])\n",
      "print (str(figRows))\n",
      "figCols = 1\n",
      "figIdPrefix = \"%d%d\" % (figRows, figCols)\n",
      "\n",
      "plt.figure(1, figsize=(8,12), dpi=100)\n",
      "for i in range(len(dictNames)):\n",
      "    if dictLens[dictNames[i]] == 0:\n",
      "        continue\n",
      "    plt.subplot(figIdPrefix + str(i))\n",
      "    name = dictNames[i]\n",
      "    plt.hist (totalCounts[name], bins=min(len(totalCounts[name]), 100))[2]\n",
      "    plt.title(name)\n",
      "\n",
      "plt.show()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "5\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAgEAAALJCAYAAAAtXfC4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlBEAAEk9AI+sWRmsU9WXAAAAAElFTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0x110c85950>"
       ]
      }
     ],
     "prompt_number": 157
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Features\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feats"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 158,
       "text": [
        "{'author': 0, 'week_of_year': 398}"
       ]
      }
     ],
     "prompt_number": 158
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(users)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 159,
       "text": [
        "363"
       ]
      }
     ],
     "prompt_number": 159
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_U = X[:,0:len(users)]\n",
      "X_W = X[:,feats['week_of_year']:(feats['month_of_year'] - 1)]\n",
      "X_M = X[:,feats['month_of_year']:X.shape[1]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "KeyError",
       "evalue": "'month_of_year'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-160-2947f399d629>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX_U\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_W\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'week_of_year'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'month_of_year'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mX_M\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'month_of_year'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mKeyError\u001b[0m: 'month_of_year'"
       ]
      }
     ],
     "prompt_number": 160
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Users\n",
      "We look at tweet rates per user. We also remove \"quiet\" users who've posted very few (less than 100) tweets. We examine the users who've posted very many tweets to ensure they're not bots."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tweetCountsPerUser = np.squeeze(np.asarray (X_U.astype(np.int32).sum(axis=0)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tweetCountsPerUser.min(), tweetCountsPerUser.max()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "quietUsers = np.where(tweetCountsPerUser < 100)[0]\n",
      "for qu in quietUsers:\n",
      "    print (users[qu])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tweetCountsPerUser.mean(), tweetCountsPerUser.std()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[np.percentile(tweetCountsPerUser, q) for q in [25, 50, 75]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lt = np.log(tweetCountsPerUser)\n",
      "np.exp(lt.mean()), np.exp(lt.std())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.hist(tweetCountsPerUser, bins=50, range=(0,5000))[2]\n",
      "plt.title(\"Tweet Counts per User\")\n",
      "plt.xlabel(\"Number of Tweets\")\n",
      "plt.ylabel(\"Number of Users\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "noisyUsers = np.where(tweetCountsPerUser > 5000)[0]\n",
      "for nu in noisyUsers:\n",
      "    print (users[nu])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "All of these actually look legitimate - some are extremely prolific users (e.g. IamLewise4fake) some are businesses (HuffPostPol and Benzinga)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So we next remove the quiet users (as inference can't reliably be performed on users with so few tweets)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "quietUser = quietUsers[0]\n",
      "quietFilter = (X[:,quietUser] == 1).todense()\n",
      "for quietUser in quietUsers:\n",
      "    quietFilter |= (X[:,quietUser] == 1).todense()\n",
      "\n",
      "noisyFilter = ~quietFilter\n",
      "noisyFilter = np.squeeze(np.asarray(noisyFilter))\n",
      "\n",
      "X_noisy = X[noisyFilter,:]\n",
      "W_noisy = W[noisyFilter,:]\n",
      "\n",
      "print (\"Stripped {:n} rows\".format(X.shape[0] - X_noisy.shape[0]))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = X_noisy\n",
      "W = W_noisy\n",
      "\n",
      "X_U = X[:,0:len(users)]\n",
      "X_W = X[:,feats['week_of_year']:(feats['month_of_year'] - 1)]\n",
      "X_M = X[:,feats['month_of_year']:X.shape[1]]\n",
      "\n",
      "D = W.shape[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_u = np.squeeze (np.asarray(np.argmax(X_U.todense(), axis=1)))\n",
      "len(y_u) == D"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###\u00a0Weeks"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tweetCountsPerWeek = np.squeeze(np.asarray (X_W.astype(np.int32).sum(axis=0)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tweetCountsPerWeek.min(), tweetCountsPerWeek.max()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tweetCountsPerWeek.mean(), tweetCountsPerWeek.std()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[np.percentile(tweetCountsPerWeek, q) for q in [25, 50, 75]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lt = np.log(tweetCountsPerWeek)\n",
      "np.exp(lt.mean()), np.exp(lt.std())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(np.arange(0, len(tweetCountsPerWeek)), tweetCountsPerWeek, 'bo')\n",
      "plt.title(\"Tweet Counts per Week\")\n",
      "plt.ylabel(\"Number of Tweets\")\n",
      "plt.xlabel(\"Week\")\n",
      "plt.ylim(0, tweetCountsPerWeek.max()* 1.10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_w = np.squeeze (np.asarray(np.argmax(X_W.todense(), axis=1)))\n",
      "len(y_w) == D"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###\u00a0Months"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "months = ['May', 'June', 'July', 'August', 'September', 'October']\n",
      "tweetCountsPerMonth = np.squeeze(np.asarray (X_M.astype(np.int32).sum(axis=0)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tweetCountsPerMonth.min(), tweetCountsPerMonth.max()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tweetCountsPerMonth.mean(), tweetCountsPerMonth.std()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[np.percentile(tweetCountsPerMonth, q) for q in [25, 50, 75]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lt = np.log(tweetCountsPerMonth)\n",
      "np.exp(lt.mean()), np.exp(lt.std())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = np.arange(0, len(tweetCountsPerMonth))\n",
      "plt.plot(x, tweetCountsPerMonth, 'bo')\n",
      "plt.title(\"Tweet Counts per Month\")\n",
      "plt.ylabel(\"Number of Tweets\")\n",
      "plt.xticks(x, months)\n",
      "plt.ylim(0, tweetCountsPerMonth.max()* 1.10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_m = np.squeeze (np.asarray(np.argmax(X_M.todense(), axis=1)))\n",
      "len(y_m) == D"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Create the All in One Dataset to Help Testing\n",
      "Bundle the (cleaned) words, features and dictionary into a single pickled blob."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if not os.path.exists(path + \"/all-in-one.pkl\"):\n",
      "    with open (path + \"/all-in-one.pkl\", \"wb\") as f:\n",
      "        pkl.dump ((W,X,d), f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Word and Feature Correlations"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#from sklearn import svm, datasets\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.metrics import roc_curve, auc\n",
      "from sklearn.cross_validation import StratifiedKFold\n",
      "\n",
      "from sklearn import cross_validation"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def cross_val_and_print_accuracy(classifier, inputs, outputs, n_folds=3):\n",
      "    '''\n",
      "    For binary and multi-class classifiers, does an n_fold \n",
      "    cross-validation and print out the accuracy of the classifer\n",
      "    and the accuracy of random\n",
      "    '''\n",
      "    skf = StratifiedKFold(outputs, n_folds=3)\n",
      "    scores = cross_validation.cross_val_score(classifier, inputs, outputs, cv=skf)\n",
      "    print(\"Classifier Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
      "    print(\"Random     Accuracy: %0.2f\" % (1.0 / (1 + np.max(outputs))))\n",
      "\n",
      "def cross_val_and_plot_roc(classifier, inputs, outputs, n_folds=3):\n",
      "    '''\n",
      "    For binary classifiers only, does an n_fold cross-validation\n",
      "    using the given instance of a classifier on the the inputs and\n",
      "    outputs and then plots the ROC curve and a line for a random\n",
      "    classifier.\n",
      "    '''\n",
      "    cv = StratifiedKFold(outputs, n_folds=n_folds)\n",
      "    \n",
      "    mean_tpr = 0.0\n",
      "    mean_fpr = np.linspace(0, 1, 100)\n",
      "    all_tpr = []\n",
      "    \n",
      "    for i, (train, test) in enumerate(cv):\n",
      "        probas_ = classifier.fit(inputs[train], outputs[train]).predict_proba(inputs[test])\n",
      "        \n",
      "        # Compute ROC curve and area the curve\n",
      "        fpr, tpr, thresholds = roc_curve(outputs[test], probas_[:, 1])\n",
      "        mean_tpr += interp(mean_fpr, fpr, tpr)\n",
      "        mean_tpr[0] = 0.0\n",
      "        roc_auc = auc(fpr, tpr)\n",
      "        \n",
      "        pl.plot(fpr, tpr, lw=1, label='ROC fold %d (area = %0.2f)' % (i, roc_auc))\n",
      "\n",
      "    pl.plot([0, 1], [0, 1], '--', color=(0.6, 0.6, 0.6), label='Luck')\n",
      "\n",
      "    mean_tpr /= len(cv)\n",
      "    mean_tpr[-1] = 1.0\n",
      "    mean_auc = auc(mean_fpr, mean_tpr)\n",
      "    pl.plot(mean_fpr, mean_tpr, 'k--',\n",
      "        label='Mean ROC (area = %0.2f)' % mean_auc, lw=2)\n",
      "\n",
      "    pl.xlim([-0.05, 1.05])\n",
      "    pl.ylim([-0.05, 1.05])\n",
      "    pl.xlabel('False Positive Rate')\n",
      "    pl.ylabel('True Positive Rate')\n",
      "    pl.title('Receiver operating characteristic example')\n",
      "    pl.legend(loc=\"lower right\")\n",
      "    pl.show()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Predicting User from Tweets"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reg = LogisticRegression()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reg.fit (W.astype(np.float64), y_u)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for u in range(len(users)):\n",
      "    words = [d[i] for i in np.where(reg.coef_[u] > 3)[0]]\n",
      "    name  = users[u]\n",
      "    print (\"%s : %s\" % (name, str(words)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cross_val_and_print_accuracy (LogisticRegression(), W, y_u)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##\u00a0Predicting Weeks from Tweets"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wreg = LogisticRegression()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wreg.fit (W.astype(np.float64), y_w)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for w in range(len(tweetCountsPerWeek)):\n",
      "    words = [d[i] for i in np.where(reg.coef_[w] > 2.5)[0]]\n",
      "    print (\"Week %d : %s\" % (w, str(words)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cross_val_and_print_accuracy (LogisticRegression(), W, y_w)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Predicting Months from Tweets"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mreg = LogisticRegression()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mreg.fit (W.astype(np.float64), y_m)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for m in range(len(tweetCountsPerMonth)):\n",
      "    words = [d[i] for i in np.where(mreg.coef_[m] > 3)[0]]\n",
      "    print (\"::: %s ::: %s\" % (months[m], str(words)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cross_val_and_print_accuracy (LogisticRegression(), W, y_m)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##\u00a0Predicting Users from HashTags"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "W_ht = W[:,dictStarts['Hashtag']:(dictEnds['Hashtag'] - 1)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "uregh = LogisticRegression()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "uregh.fit (W_ht.astype(np.float64), y_u)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for u in range(len(users)):\n",
      "    words = [d[i + dictStarts['Hashtag']] for i in np.where(uregh.coef_[u] > 4)[0]]\n",
      "    name  = users[u]\n",
      "    print (\"%s : %s\" % (name, str(words)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cross_val_and_print_accuracy (LogisticRegression(), W_ht, y_u)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Predicting Months from HashTags"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mregh = LogisticRegression()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mregh.fit (W_ht.astype(np.float64), y_m)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for m in range(len(tweetCountsPerMonth)):\n",
      "    words = [d[i + dictStarts['Hashtag']] for i in np.where(mregh.coef_[m] > 3)[0]]\n",
      "    print (\"::: %s ::: %s\" % (months[m], str(words)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cross_val_and_print_accuracy (LogisticRegression(), W_ht, y_m)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Performance of Topic Models\n",
      "We test the performance of existing topic models on this dataset, in order to determine a baseline through which performance can be measured.\n",
      "\n",
      "The data is condense in two forms: the first is the standard layout for an author-topic model (i.e. each \"document\" is all an author's tweets). The second is a \"temporal\" author-topic model, where we for each month we create documents containing all a user's tweets for that month. This is just to see if certain topics are more prevalent in certain months.\n",
      "\n",
      "We try the built-in LDA implementation from Scipy, and then our implementation of the CTM model \n",
      "\n",
      "However first we need to define methods to display the results"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.display import HTML\n",
      "from IPython.display import Latex\n",
      "from IPython.display import Image\n",
      "\n",
      "def printTopics(wordDict, vocab, count=10):\n",
      "    words = vocab.argsort()[-count:][::-1]\n",
      "    for wordIdx in words:\n",
      "        print(\"%5.3f - %s\" % (vocab[wordIdx], wordDict[wordIdx]))\n",
      "    print(\"\")\n",
      "  \n",
      "# Create a nice number of table cells first for each topic\n",
      "# (including padding with &nbsp; cells\n",
      "# then iterate through and add to table, safe in the knowledge\n",
      "# that there's the expected number of cells\n",
      "    \n",
      "def createTopicsTable(wordDict, vocabs, count=10):\n",
      "    MaxWordLen   = 10\n",
      "    K,V = vocabs.shape\n",
      "    \n",
      "    tab = \"<table border=1 style='font-size: 10px'>\"\n",
      "    for k in range(K):\n",
      "        vocab = vocabs[k,:]\n",
      "        popularWordIndices = vocab.argsort()[-count:][::-1]\n",
      "        tab += \"<tr><th rowspan=2>Topic \" + str(k) + \"</th>\"\n",
      "        tab += \"<td>\" + \"</td><td>\".join(d[w][:MaxWordLen] for w in popularWordIndices) + \"</td></tr>\"\n",
      "        tab += \"<tr><td>\" + \"</td><td>\".join(\"%5.3f\" % vocab[w] for w in popularWordIndices) + \"</td></tr>\"\n",
      "      \n",
      "    tab += \"</table>\"\n",
      "    return HTML(tab)\n",
      "\n",
      "def createTopicsTableLatex(wordDict, vocabs, count=10):\n",
      "    MaxWordLen   = 15\n",
      "    K,V = vocabs.shape\n",
      "    \n",
      "    tab = \"\\\\begin{tabular}{| r |\" + \"| c \" * count + \"|} \\n\"\n",
      "    tab += \"\\\\hline \\n\"\n",
      "    for k in range(K):\n",
      "        vocab = vocabs[k,:]\n",
      "        popularWordIndices = vocab.argsort()[-count:][::-1]\n",
      "        tab += \"Topic \" + str(k) + \" & \"\n",
      "        tab += \" & \".join(d[w][:MaxWordLen] for w in popularWordIndices) + \" \\\\\\\\ \\n\"\n",
      "        tab += \"a & \" + \" & \".join(\"%5.3f\" % vocab[w] for w in popularWordIndices) + \" \\\\\\\\ \\\\hline \\n\"\n",
      "      \n",
      "    tab += \"\\\\hline\\n\\\\end{tabular}\\n\"\n",
      "    return Latex(tab)\n",
      "\n",
      "\n",
      "def createTopicsTableAscii(wordDict, vocabs, count=10):\n",
      "    MaxWordLen   = 15\n",
      "    NumLen       = 6\n",
      "    sfmt = \"%\" + str(MaxWordLen) + \"s\"\n",
      "    nfmt = \"%\" + str(NumLen) + \".\" + str(NumLen - 2) + \"f\" + \" \" * (MaxWordLen - NumLen)\n",
      "    K,V = vocabs.shape\n",
      "    \n",
      "    tab = \"\"\n",
      "    for k in range(K):\n",
      "        vocab = vocabs[k,:]\n",
      "        popularWordIndices = vocab.argsort()[-count:][::-1]\n",
      "        tab += \"Topic %3d  \" % k\n",
      "        tab += \"  \".join(sfmt % d[w][:MaxWordLen] for w in popularWordIndices) + \" \\n\"\n",
      "        tab += \"           \" + \"  \".join(nfmt % vocab[w] for w in popularWordIndices) + \" \\n\"\n",
      "      \n",
      "    return tab\n",
      "            "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 161
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Condensing the dataset into author-documents"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# The total number of users\n",
      "tweeterTopicPath = path + \"/words-by-author.pkl\"\n",
      "\n",
      "if os.path.exists(tweeterTopicPath):\n",
      "    with open (tweeterTopicPath, 'rb') as f:\n",
      "        user_dict, _, W_U = pkl.load(f)\n",
      "else:\n",
      "    X_U_total = np.asarray(np.squeeze (np.sum(X_U.todense(), axis=0)))\n",
      "    zero_tweet_users=np.where(X_U_total ==0)[1]\n",
      "    \n",
      "    totalUserCount = X_U.shape[1]\n",
      "    \n",
      "    user_dict = []\n",
      "    D_u = totalUserCount - zero_tweet_users.shape[0]\n",
      "    W_U = ssp.lil_matrix((D_u, W.shape[1]), dtype=W.dtype)\n",
      "    \n",
      "    uIdx = 0\n",
      "    for u in range(totalUserCount):\n",
      "        if u in zero_tweet_users:\n",
      "            continue\n",
      "        \n",
      "        user_dict.append(users[u])\n",
      "        W_U[uIdx,:] = ssp.lil_matrix(W[np.where(y_u==u)[0],:]).sum(axis=0)\n",
      "        \n",
      "        uIdx += 1\n",
      "    \n",
      "    W_U = W_U.tocsr()\n",
      "\n",
      "    with open(tweeterTopicPath, 'wb') as f:\n",
      "        pkl.dump((user_dict, d, W_U), f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ValueError",
       "evalue": "zero-size array to reduction operation maximum which has no identity",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-162-7e2470e78b69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0muser_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mW_U\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muIdx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mssp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlil_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_u\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0muIdx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/3.3/lib/python3.3/site-packages/scipy/sparse/csr.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0;31m# [[1,2],??]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misintlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m                 \u001b[0mP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m# [[1,2],j] or [[1,2],1:2]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0missequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m                     \u001b[0;31m# [[1,2],[1,2]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/3.3/lib/python3.3/site-packages/scipy/sparse/csr.py\u001b[0m in \u001b[0;36mextractor\u001b[0;34m(indices, N)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masindices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m             \u001b[0;34m(\u001b[0m\u001b[0mmin_indx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_indx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_bounds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmin_indx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/3.3/lib/python3.3/site-packages/scipy/sparse/csr.py\u001b[0m in \u001b[0;36mcheck_bounds\u001b[0;34m(indices, N)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcheck_bounds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m             \u001b[0mmax_indx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmax_indx\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'index (%d) out of range'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmax_indx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/3.3/lib/python3.3/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_amax\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_amax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     return um.maximum.reduce(a, axis=axis,\n\u001b[0;32m---> 17\u001b[0;31m                             out=out, keepdims=keepdims)\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_amin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"
       ]
      }
     ],
     "prompt_number": 162
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Just as a sanity check we look at the word distribution for a user known as `FakeFernando` who has an interest in formula one racing and pop culture. We would expect to see mentions of Lewis Hamilton, \"Nando\" and references to the BBC F1 coverage."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "FakeFernandosTweets = W[np.where(y_u==users.index(\"FakeFernando\"))[0],:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "These are the words from a sample tweet"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[d[w] for w in FakeFernandosTweets[1010,:].indices]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "FatFakeFernandosTweets = np.asarray(FakeFernandosTweets.todense())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#printTopics(d, FatFakeFernandosTweets.sum(axis=0), count=50)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## A Simple K-Means Clustering"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cluster import KMeans\n",
      "from sklearn.preprocessing import normalize"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "W_U_TF = W_U.copy().astype(np.float64)\n",
      "W_U_TF = normalize (W_U_TF, norm='l1', axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cluster = KMeans(n_clusters=20, init='k-means++', precompute_distances=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "result = cluster.fit(W_U_TF)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "h = createTopicsTable(d, cluster.cluster_centers_, count=40)\n",
      "h"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Latex(r\"\"\"This is {\\bf text}\"\"\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## An implementation of the Correlated Topic Model using Bouchard's Bound"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import model\n",
      "\n",
      "import pickle as pkl\n",
      "with open(\"/Users/bryanfeeney/Desktop/author_ctm_result.pkl\", \"rb\") as f:\n",
      "    (a_model, a_query) = pkl.load(f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The number of topics"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a_model.K"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Evolution of the Variational Bound"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Image(\"/Users/bryanfeeney/Desktop/real_author_ctm_bound.png\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### The Inferred Covariance and Topic Means"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig, ax = plt.subplots(figsize=(11,9))\n",
      "\n",
      "im = plt.imshow(a_model.sigT, interpolation=\"none\")\n",
      "\n",
      "cb = fig.colorbar(im, ax=ax)\n",
      "ax.set_title(\"Covariance Matrix\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next we plot the topic distributions for all the various users."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from util.array_utils import rowwise_softmax\n",
      "\n",
      "dist = rowwise_softmax(a_query.means)\n",
      "fig, ax = plt.subplots(figsize=(10,30))\n",
      "\n",
      "im = plt.imshow(dist, interpolation=\"none\")\n",
      "\n",
      "cb = fig.colorbar(im, ax=ax)\n",
      "ax.set_title(\"Means Matrix\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As observed previously, we have incredibly hard assignments to topics, which possibly could be due to the tendendcy of the softmax function to prefer extremes. Only one user is split between two and then one is still very much preferred."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(dist[205,:] * 100).astype(np.int32)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "user_dict[205]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dist[205,:].argsort()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The interesting thing about this, is that topic 27 is a Spanish only topic."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### The Table of Word Distributions Per Topic"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "h = createTopicsTable(d, a_model.vocab, count=30)\n",
      "h"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Our Topic Model with Features Inferring Topics per tweet.\n",
      "\n",
      "In this run we assume that the dimension of the latent space $P=100$, from a total feature-space of $F=427$. We infer $K=30$ topics for over 600,000 tweets from nearly 350 users."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import model\n",
      "\n",
      "import pickle as pkl\n",
      "with open(\"/Users/bryanfeeney/Desktop/test_result_real.pkl\", \"rb\") as f:\n",
      "    (t_model, t_query) = pkl.load(f)\n",
      "\n",
      "(t_model.P, t_model.K)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Evolution of the Variational Bound"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Image(filename=\"/Users/bryanfeeney/Desktop/real_stm_bound.png\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Inferred Variance and Topic Means\n",
      "Next we display the _diagonal_ covariance over topics. We've forced this to be diagonal for performance reasons, but not isotropic. Nevertheless there is little difference in the variances around the different topic estimates."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig, ax = plt.subplots(figsize=(11,9))\n",
      "\n",
      "im = plt.imshow(t_model.sigT, interpolation=\"none\")\n",
      "\n",
      "cb = fig.colorbar(im, ax=ax)\n",
      "ax.set_title(\"Covariance Matrix\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next we try to visually display the topic distributions for a few known users. The first user, \"FakeFernando\" follows formula one racing, and also pop-culture. For brevity we only plot a subset. Note that tweets are read in, and therefore processed, in chronological order, so we can view tweet distribution change over time."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from util.array_utils import rowwise_softmax"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fakeFernandoFlags   = np.squeeze(np.asarray(X_U[:,users.index(\"FakeFernando\")].todense()))\n",
      "fakeFernandosTweets = np.where(fakeFernandoFlags == 1)\n",
      "fakeFernandosDist = rowwise_softmax((t_query.means[fakeFernandosTweets,:])[0])\n",
      "fakeFernandosDistSubset = fakeFernandosDist[0:200,:]\n",
      "\n",
      "fig, ax = plt.subplots(figsize=(10,20))\n",
      "\n",
      "im = plt.imshow(fakeFernandosDistSubset, interpolation=\"none\")\n",
      "\n",
      "cb = fig.colorbar(im, ax=ax)\n",
      "ax.set_title(\"FakeFernando's Tweets Matrix\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fakeFernandosDist.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "At first glance the above distribution looks interesting, until we see the scale and realise that it's almost entirely uniform with a few exceptions. The tweets are processed in chronological order, so the changes in topic distribution are occurring over time.\n",
      "\n",
      "The America Civil Liberies Union (ACLU) campaigns for various US related causes, and during this time was particularly engaged with women's rights, which were in the news over this period. For reasons of space we just consider a few of their tweets."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "acluFlags   = np.squeeze(np.asarray(X_U[:,users.index(\"ACLU\")].todense()))\n",
      "aclusTweets = np.where(acluFlags == 1)\n",
      "aclusDist = rowwise_softmax((t_query.means[aclusTweets,:])[0])\n",
      "aclusDistSubset = aclusDist[300:500,:]\n",
      "\n",
      "fig, ax = plt.subplots(figsize=(10,20))\n",
      "\n",
      "im = plt.imshow(aclusDistSubset, interpolation=\"none\")\n",
      "\n",
      "cb = fig.colorbar(im, ax=ax)\n",
      "ax.set_title(\"ACLU's Tweets Matrix\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "aclusDist.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "h =  createTopicsTable(d, t_model.vocab, count=100)\n",
      "h"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###\u00a0Posterior Covariance of the Latent Space"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "fig, ax = plt.subplots(figsize=(10,12))\n",
      "\n",
      "im = plt.imshow(t_model.R_Y, interpolation=\"none\")\n",
      "\n",
      "cb = fig.colorbar(im, ax=ax)\n",
      "ax.set_title(\"Posterior Covariance of the Latent Feature Space\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Posterior Covariance of the Full Feature Space"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig, ax = plt.subplots(figsize=(14,16))\n",
      "\n",
      "im = plt.imshow(t2_model.R_A, interpolation=\"none\")\n",
      "\n",
      "cb = fig.colorbar(im, ax=ax)\n",
      "ax.set_title(\"Posterior Covariance of the Feature Space\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## A Second Run of Our Topic Model with Features Inferring Topics per tweet.\n",
      "\n",
      "In this run we assume that the dimension of the latent space $P=30$, from a total feature-space of $F=427$. We infer $K=10$ topics for over 600,000 tweets from nearly 350 users."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import model\n",
      "\n",
      "import pickle as pkl\n",
      "with open(\"/Users/bryanfeeney/Desktop/test_result_real_p30_k10.pkl\", \"rb\") as f:\n",
      "    (t2_model, t2_query) = pkl.load(f)\n",
      "\n",
      "(t2_model.P, t2_model.K)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Evolution of the Variational Bound"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Image(filename=\"/Users/bryanfeeney/Desktop/real_stm_bound_p30_k10.png\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Inferred Variance and Topic Means\n",
      "Next we display the _diagonal_ covariance over topics. We've forced this to be diagonal for performance reasons, but not isotropic. Nevertheless there is little difference in the variances around the different topic estimates."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig, ax = plt.subplots(figsize=(11,9))\n",
      "\n",
      "im = plt.imshow(t2_model.sigT, interpolation=\"none\")\n",
      "\n",
      "cb = fig.colorbar(im, ax=ax)\n",
      "ax.set_title(\"Covariance Matrix\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next we try to visually display the topic distributions for a few known users. The first user, \"FakeFernando\" follows formula one racing, and also pop-culture. For brevity we only plot a subset. Note that tweets are read in, and therefore processed, in chronological order, so we can view tweet distribution change over time."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fakeFernandoFlags   = np.squeeze(np.asarray(X_U[:,users.index(\"FakeFernando\")].todense()))\n",
      "fakeFernandosTweets = np.where(fakeFernandoFlags == 1)\n",
      "fakeFernandosDist = rowwise_softmax((t2_query.means[fakeFernandosTweets,:])[0])\n",
      "fakeFernandosDistSubset = fakeFernandosDist[0:200,:]\n",
      "\n",
      "fig, ax = plt.subplots(figsize=(10,35))\n",
      "\n",
      "im = plt.imshow(fakeFernandosDistSubset, interpolation=\"none\")\n",
      "\n",
      "cb = fig.colorbar(im, ax=ax)\n",
      "ax.set_title(\"FakeFernando's Tweets Matrix\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is much more differentiated than before with $P=100$ and $K=10$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "acluFlags   = np.squeeze(np.asarray(X_U[:,users.index(\"ACLU\")].todense()))\n",
      "aclusTweets = np.where(acluFlags == 1)\n",
      "aclusDist = rowwise_softmax((t2_query.means[aclusTweets,:])[0])\n",
      "aclusDistSubset = aclusDist[300:500,:]\n",
      "\n",
      "fig, ax = plt.subplots(figsize=(10,35))\n",
      "\n",
      "im = plt.imshow(aclusDistSubset, interpolation=\"none\")\n",
      "\n",
      "cb = fig.colorbar(im, ax=ax)\n",
      "ax.set_title(\"ACLU's Tweets Matrix\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note that topic 5 is closely related to politics"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "h =  createTopicsTable(d, t2_model.vocab, count=100)\n",
      "h"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Inferred Low-Rank Feature Covariance"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "fig, ax = plt.subplots(figsize=(10,12))\n",
      "\n",
      "im = plt.imshow(t2_model.R_Y, interpolation=\"none\")\n",
      "\n",
      "cb = fig.colorbar(im, ax=ax)\n",
      "ax.set_title(\"Posterior Covariance of the Latent Feature Space\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Inferred Full-Rank Feature Covariance\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig, ax = plt.subplots(figsize=(14,16))\n",
      "\n",
      "im = plt.imshow(t2_model.R_A, interpolation=\"none\")\n",
      "\n",
      "cb = fig.colorbar(im, ax=ax)\n",
      "ax.set_title(\"Posterior Covariance of the Feature Space\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Investigating the Strange Posterior Covariance of X"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X.dtype\n",
      "Xf = X.astype(np.float32)\n",
      "\n",
      "S = Xf.T.dot(Xf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So one thing to note is that there were more slots allowed for users in the matrix than were actually taken up. This was just due to certain users not having any valid (more than three word) tweets, or not tweeting at all. We can see the difference by comparing the feature offsets (users start at 0) with the actual size of the users dictionary"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feats"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(users)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "With that in mind we can focus on the variables which are simply related to time (week and month)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_time = X[:,398:X.shape[1]].astype(np.float32).todense()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig, ax = plt.subplots(figsize=(14,16))\n",
      "\n",
      "im = plt.imshow(X_time.T.dot(X_time), interpolation=\"none\")\n",
      "\n",
      "cb = fig.colorbar(im, ax=ax)\n",
      "ax.set_title(\"Time Feature Covariance\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is the oddly shaped square at the bottom of the overall covariance plot. Obviously there are a little over four weeks per month whic overloap. The strange boxy colours seem just to be due to image aliasing artefacts"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}